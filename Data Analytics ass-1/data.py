# ğŸ“¦ Import Libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

# ğŸ“‚ Load Dataset
df = pd.read_csv("user_behavior.csv")  # Change filename if needed

# ğŸ‘ Initial Exploration
print("ğŸ” Dataset shape:", df.shape)
print("ğŸ§± Columns:", df.columns.tolist())
print("ğŸ“Š Data types:\n", df.dtypes)
print("â“ Missing values:\n", df.isnull().sum())
print("ğŸ” Duplicate rows:", df.duplicated().sum())
print("ğŸ‘€ First few rows:\n", df.head())

# ğŸ§¹ Data Cleaning

# Drop columns with more than 50% missing values
df = df[df.columns[df.isnull().mean() < 0.5]]

# Remove duplicates
df = df.drop_duplicates()

# ğŸ§½ Fill missing values
num_cols = df.select_dtypes(include=['int64', 'float64']).columns
cat_cols = df.select_dtypes(include=['object']).columns

df[num_cols] = df[num_cols].fillna(df[num_cols].mean())
df[cat_cols] = df[cat_cols].fillna(df[cat_cols].mode().iloc[0])

# ğŸ”¡ Encode categorical variables
df = pd.get_dummies(df, drop_first=True)

# ğŸ—‘ Drop non-useful columns (like IDs or timestamps)
df = df.drop(columns=['user_id', 'timestamp'], errors='ignore')

# ğŸ“ Feature Scaling
scaler = StandardScaler()
df[df.columns] = scaler.fit_transform(df)

# ğŸ“Š EDA Visualization
plt.figure(figsize=(10, 6))
sns.heatmap(df.corr(), annot=False, cmap="coolwarm")
plt.title("Correlation Heatmap")
plt.show()

# Optional: Plot one column (if available)
if "age" in df.columns:
    sns.histplot(df["age"], kde=True)
    plt.title("Age Distribution")
    plt.show()

# ğŸ¯ Train-Test Split (if target available)
target = "purchase" if "purchase" in df.columns else None
if target:
    X = df.drop(target, axis=1)
    y = df[target]
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    print("âœ… Train-test split done")
else:
    print("âš ï¸ No target variable found. Dataset ready for clustering or analysis.")

# ğŸ§¾ Final Data Snapshot
print("ğŸ“Œ Final dataset shape:", df.shape)
print("ğŸ“ˆ Summary statistics:\n", df.describe())
